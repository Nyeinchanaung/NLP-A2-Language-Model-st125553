{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyBb2AsVgNIO"
   },
   "source": [
    "# LSTM Language Models\n",
    "\n",
    "You guys probably very excited about ChatGPT.  In today class, we will be implementing a very simple language model, which is basically what ChatGPT is, but with a simple LSTM.  You will be surprised that it is not so difficult at all.\n",
    "\n",
    "Paper that we base on is *Regularizing and Optimizing LSTM Language Models*, https://arxiv.org/abs/1708.02182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1832,
     "status": "ok",
     "timestamp": 1737875015859,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "eL3c0nw3XaG-",
    "outputId": "ca3ce79f-a339-421e-ae65-d33296f55540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torchtext torch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42295,
     "status": "ok",
     "timestamp": 1737875061206,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "Fd-Ni3JhW_Gz",
    "outputId": "6a56d1f3-ab75-484a-c836-014df5741436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.1.0\n",
      "  Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision==0.16.0\n",
      "  Using cached torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
      "Collecting triton==2.1.0 (from torch==2.1.0)\n",
      "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2024.12.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
      "Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Installing collected packages: triton, nvidia-nccl-cu12, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.18.1 torch-2.1.0 torchvision-0.16.0 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.0 torchvision==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1737874030689,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "cCiXYEPvss6a"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5567,
     "status": "ok",
     "timestamp": 1737875132140,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "3y_vrqz4bawx",
    "outputId": "d4075953-61c2-4fd2-a2ac-8934da8b1c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.16.0\n",
      "  Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (1.26.4)\n",
      "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
      "  Downloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.1.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
      "Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.7.0 torchtext-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5619,
     "status": "ok",
     "timestamp": 1737875140180,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "O1zKbCMss9ap",
    "outputId": "d040690f-9fd0-455f-d9ac-12fe67ef193b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.1.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /usr/local/lib/python3.11/dist-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchtext, torchvision\n",
      "Name: torchtext\n",
      "Version: 0.16.0\n",
      "Summary: Text utilities, models, transforms, and datasets for PyTorch.\n",
      "Home-page: https://github.com/pytorch/text\n",
      "Author: PyTorch Text Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD\n",
      "Location: /usr/local/lib/python3.11/dist-packages\n",
      "Requires: numpy, requests, torch, torchdata, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch\n",
    "!pip show torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737874500637,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "bVAyxaKJtIzU"
   },
   "outputs": [],
   "source": [
    "# For M1 mac in local\n",
    "# pip install torch==2.1.0 torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4265,
     "status": "ok",
     "timestamp": 1737875168573,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "2j4lw9vdbnpv",
    "outputId": "5f74e046-a020-429d-f483-bdd70cfc3254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1737875211103,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "KWAuc372gNIQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "import torchtext, datasets, math\n",
    "from tqdm import tqdm\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1737875214553,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "2wMQ-A-0gNIQ",
    "outputId": "82c02c85-0dec-4a9c-c703-886fdade5c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1737875215702,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "wCXc90SSgNIR"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25079,
     "status": "ok",
     "timestamp": 1737884465407,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "Zdmo7eRv5qsP",
    "outputId": "5b0b8033-cff0-40ee-e7fb-9670555ebf68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# connect to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1737884465742,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "6KgevSOA5uE3"
   },
   "outputs": [],
   "source": [
    "# mount drive folder\n",
    "#import os\n",
    "import os\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/_NLP/A2/NLP-A2-Language-Model-st125553')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL4evKOXW_G4"
   },
   "source": [
    "## 0. Prepare Dataset\n",
    "- use the data from kaggle (https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwHKC6HwW_G5"
   },
   "source": [
    "#### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1737885063290,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "jJfMaa2fW_G5",
    "outputId": "36c2bd66-8e82-473d-a797-489c732deb3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/tgdivy/poetry-foundation-poems/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tgdivy/poetry-foundation-poems\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1737885069599,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "GsUzcMhQW_G5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/PoetryFoundationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737885070942,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "5wsRggDJW_G5",
    "outputId": "b48ece63-f650-4028-9ee8-a325b6a5ef11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Title  \\\n",
      "0           0  \\r\\r\\n                    Objects Used to Prop...   \n",
      "1           1  \\r\\r\\n                    The New Church\\r\\r\\n...   \n",
      "2           2  \\r\\r\\n                    Look for Me\\r\\r\\n   ...   \n",
      "3           3  \\r\\r\\n                    Wild Life\\r\\r\\n     ...   \n",
      "4           4  \\r\\r\\n                    Umbrella\\r\\r\\n      ...   \n",
      "\n",
      "                                                Poem              Poet Tags  \n",
      "0  \\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...  Michelle Menting  NaN  \n",
      "1  \\r\\r\\nThe old cupola glinted above the clouds,...     Lucia Cherciu  NaN  \n",
      "2  \\r\\r\\nLook for me under the hood\\r\\r\\nof that ...        Ted Kooser  NaN  \n",
      "3  \\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...   Grace Cavalieri  NaN  \n",
      "4  \\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...      Connie Wanek  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1737885073230,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "ua9HRABwW_G5",
    "outputId": "0d880399-1549-4b83-94c2-e3ea9a3c883b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicates: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1737885074500,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "82f0tw5AW_G5"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1737885076318,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "7w2sS0UaW_G5",
    "outputId": "4ca03384-5cab-4257-9c12-36f04f71bbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "Title           0\n",
      "Poem            0\n",
      "Poet            0\n",
      "Tags          955\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1737885079850,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "60JQsB14W_G5"
   },
   "outputs": [],
   "source": [
    "df[\"Poem\"] = df[\"Poem\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1737885081562,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "jZSre2oQW_G6"
   },
   "outputs": [],
   "source": [
    "# Example of removing unwanted phrases\n",
    "df[\"Poem\"] = df[\"Poem\"].str.replace(\"Poem ends here\", \"\", regex=False).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1737885084951,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "ND2C6MXdW_G6"
   },
   "outputs": [],
   "source": [
    "# Check poem lengths\n",
    "df[\"poem_length\"] = df[\"Poem\"].str.split().apply(len)\n",
    "\n",
    "# Remove very short or very long poems\n",
    "df = df[df[\"poem_length\"] > 5]  # Remove poems with fewer than 5 words\n",
    "df = df[df[\"poem_length\"] < 512]  # Remove poems with more than 512 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737885086309,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "YtS_b8whW_G6"
   },
   "outputs": [],
   "source": [
    "cleaned_texts = df[\"Poem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737885096172,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "q4xFq3A1BftR",
    "outputId": "418cbb0c-a830-4f16-b236-208eee4c4784"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog bone, stapler, cribbage board, garlic pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The old cupola glinted above the clouds, shone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Look for me under the hood of that old Chevrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Behind the silo, the Mother Rabbit hunches lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I push your button you fly off the handle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0    Dog bone, stapler, cribbage board, garlic pres...\n",
       "1    The old cupola glinted above the clouds, shone...\n",
       "2    Look for me under the hood of that old Chevrol...\n",
       "3    Behind the silo, the Mother Rabbit hunches lik...\n",
       "4    When I push your button you fly off the handle...\n",
       "Name: Poem, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScHv3lxJW_G6"
   },
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1737885104869,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "MuCtql5mW_G6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine all cleaned texts into a single dataset\n",
    "full_dataset = \" \".join(cleaned_texts)\n",
    "\n",
    "# Split into sentences for simplicity\n",
    "sentences = full_dataset.split(\". \")\n",
    "\n",
    "# Train-validation-test split\n",
    "train_data, temp_data = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert back to text for storage\n",
    "train_text = \" \".join(train_data)\n",
    "validation_text = \" \".join(validation_data)\n",
    "test_text = \" \".join(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DqVPNm1W_G6"
   },
   "source": [
    "#### Create DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1737885112520,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "X4Z3IWQZW_G6",
    "outputId": "910cbe2b-77ee-4107-c2f2-1921479ebcf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 72816\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 9102\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 9102\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Create individual datasets\n",
    "train_dataset = Dataset.from_dict({\"text\": train_data})\n",
    "validation_dataset = Dataset.from_dict({\"text\": validation_data})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_data})\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Inspect the DatasetDict\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeEPgy8DgNIR"
   },
   "source": [
    "## 1. Load data - Poem Dataset\n",
    "\n",
    "I will be using dataset from  which contains a large corpus of text, perfect for language modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1737885118913,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "Nsn3YQ3sW_G7",
    "outputId": "c9012a4e-323c-43a8-b5ee-79d213e6451e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'In the long, cool slant of sun, spent flowers fold into cups'}\n",
      "{'text': '\\ufeff\\ufeff1 Under the long green hair of pepper trees, The writers and composers work the street'}\n",
      "{'text': 'At last, as they exhausted slept, Death granted the divorce, And nakedly the woman leapt Upon that narrow horse'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "#dataset = load_dataset(\"nyeinchanaung/nca_poem\")\n",
    "\n",
    "# Access train, validation, and test splits\n",
    "print(dataset[\"train\"][0])\n",
    "print(dataset[\"validation\"][0])\n",
    "print(dataset[\"test\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737875238823,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "ZBki8fRkgNIR"
   },
   "outputs": [],
   "source": [
    "#dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1737885122513,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "GWyvgpKJW_G7",
    "outputId": "1da2700a-1adf-4d9f-fa20-32aefcd178ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 72816\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 9102\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 9102\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load a similar dataset from the datasets library\n",
    "#dataset = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "\n",
    "# Inspect the dataset structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1737885133268,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "d990dZ18gNIS",
    "outputId": "4902f3c5-2ca2-487d-8e84-adfc18f1c504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72816, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q81u3117gNIT"
   },
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtxjJVPzgNIT"
   },
   "source": [
    "### Tokenizing\n",
    "\n",
    "Simply tokenize the given text to tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "f7adc43502ef43ef820881de2101c164",
      "c6ad48b766334141b1d83a164c694212",
      "439cc7aca2604e31bf7a1a438e6c207c",
      "00a1b4511a3144a2a919cb822f71f693",
      "1eeb99ca22c342069d33b6fae1f4017f",
      "d43fddb3cd544d4a9c27151d2d73a43c",
      "900ac4d1f4f54797b2388d777ab37197",
      "ff299a29bd794f65bffc5afebf25a08c",
      "7448d3c87600403f850c1b11091cadbc",
      "a311d8d045e94cd389b7eac7ca75424e",
      "598afe639ee14c24b898db8db7acbf35",
      "864766d852b54e389eaaf5ce6b95d7b9",
      "79716e5177324c57b762e70c6ef1de48",
      "521d4ae75430408b8a095187c9d7c009",
      "25439d3b31e74d008f2d5671efe2e10f",
      "7cdcf56e94b44ffba2d32d78ae0ee677",
      "85d9b10c1cab4c788955729fd0812a0d",
      "b03122a63c3e4839b8ce35b9ffd648f8",
      "5665e5ee3d564db59871b3c097e9b7f2",
      "59cd518511c14f8b8597a6111769c27b",
      "e708c16828274a6187abed31982fc17f",
      "0b469d200c324c47b782f084c0d3e43d",
      "786c0c40bcb74b9e80a8fbe386f467a4",
      "1d7174f49f9c45c4bea22cbe2c2a166a",
      "6e606082e7cf4322ae384b0998c6c870",
      "afb75a221e264882bcd4155c86415060",
      "c9a7133468304f76ab45d141fe9b9a51",
      "d049fb9058ae4b4d8e7b0f3423c6dbd4",
      "7b32a7bcbd9a4589b178837590d77e98",
      "7006cd37f86142c693ad2c1d61fa87d5",
      "cd0556ca3bcb424cba3fbcbe72b72f7a",
      "b4abfbe5691e4fd399903a384b518271",
      "a392f6a53c2148ce96ef638bd5d52d7f"
     ]
    },
    "executionInfo": {
     "elapsed": 5732,
     "status": "ok",
     "timestamp": 1737885141745,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "HczwO0U2gNIT",
    "outputId": "356e13ed-c51e-4f03-f458-bb6cf898a102"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7adc43502ef43ef820881de2101c164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864766d852b54e389eaaf5ce6b95d7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786c0c40bcb74b9e80a8fbe386f467a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "\n",
    "tokenize_data = lambda example, tokenizer: {'tokens': tokenizer(example['text'])}\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_data, remove_columns=['text'], fn_kwargs={'tokenizer': tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1737885143682,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "nI-ThnDMgNIT",
    "outputId": "ec80993b-262b-402e-eb03-d2ad7deefce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maybe', ',', 'beyond', 'briefcases', ',', 'we', 'have', 'some', 'thingsin', 'common']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][223]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5x7g7YmgNIU"
   },
   "source": [
    "### Numericalizing\n",
    "\n",
    "We will tell torchtext to add any word that has occurred at least three times in the dataset to the vocabulary because otherwise it would be too big.  Also we shall make sure to add `unk` and `eos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "executionInfo": {
     "elapsed": 2262,
     "status": "ok",
     "timestamp": 1737885150512,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "sSuoQRnngNIU"
   },
   "outputs": [],
   "source": [
    "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_dataset['train']['tokens'], min_freq=3)\n",
    "vocab.insert_token('<unk>', 0)\n",
    "vocab.insert_token('<eos>', 1)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1737885152447,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "eN6KPF76gNIU",
    "outputId": "d25703d0-be00-4615-d060-d4c11c65361a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26763\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1737885156114,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "Mqaf8o6VgNIU",
    "outputId": "4a4d7911-2022-498a-daad-7cf844c2f21b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<eos>', ',', 'the', 'and', 'of', 'a', 'to', 'in', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QIrQM4lgNIU"
   },
   "source": [
    "## 3. Prepare the batch loader\n",
    "\n",
    "### Prepare data\n",
    "\n",
    "Given \"Chaky loves eating at AIT\", and \"I really love deep learning\", and given batch size = 3, we will get three batches of data \"Chaky loves eating at\", \"AIT `<eos>` I really\", \"love deep learning `<eos>`\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1737885161554,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "soPHgJt5gNIU"
   },
   "outputs": [],
   "source": [
    "def get_data(dataset, vocab, batch_size):\n",
    "    data = []\n",
    "    for example in dataset:\n",
    "        if example['tokens']:\n",
    "            tokens = example['tokens'].append('<eos>')\n",
    "            tokens = [vocab[token] for token in example['tokens']]\n",
    "            data.extend(tokens)\n",
    "    data = torch.LongTensor(data)\n",
    "    num_batches = data.shape[0] // batch_size\n",
    "    data = data[:num_batches * batch_size]\n",
    "    data = data.view(batch_size, num_batches) #view vs. reshape (whether data is contiguous)\n",
    "    return data #[batch size, seq len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 6072,
     "status": "ok",
     "timestamp": 1737885169079,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "8XjvyxqvgNIU"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = get_data(tokenized_dataset['train'], vocab, batch_size)\n",
    "valid_data = get_data(tokenized_dataset['validation'], vocab, batch_size)\n",
    "test_data  = get_data(tokenized_dataset['test'],  vocab, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1737885169079,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "6dClHIrYgNIU",
    "outputId": "b300d3ea-2603-4496-ad09-8241c1abf598"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 15408])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9d1N8nGgNIU"
   },
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1737885174948,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "qAX_znz8gNIU"
   },
   "outputs": [],
   "source": [
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hid_dim    = hid_dim\n",
    "        self.emb_dim    = emb_dim\n",
    "\n",
    "        self.embedding  = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm       = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, dropout=dropout_rate, batch_first=True)\n",
    "        self.dropout    = nn.Dropout(dropout_rate)\n",
    "        self.fc         = nn.Linear(hid_dim, vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range_emb = 0.1\n",
    "        init_range_other = 1/math.sqrt(self.hid_dim)\n",
    "        self.embedding.weight.data.uniform_(-init_range_emb, init_range_other)\n",
    "        self.fc.weight.data.uniform_(-init_range_other, init_range_other)\n",
    "        self.fc.bias.data.zero_()\n",
    "        for i in range(self.num_layers):\n",
    "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.emb_dim,\n",
    "                self.hid_dim).uniform_(-init_range_other, init_range_other) #We\n",
    "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.hid_dim,\n",
    "                self.hid_dim).uniform_(-init_range_other, init_range_other) #Wh\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n",
    "        cell   = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n",
    "        return hidden, cell\n",
    "\n",
    "    def detach_hidden(self, hidden):\n",
    "        hidden, cell = hidden\n",
    "        hidden = hidden.detach() #not to be used for gradient computation\n",
    "        cell   = cell.detach()\n",
    "        return hidden, cell\n",
    "\n",
    "    def forward(self, src, hidden):\n",
    "        #src: [batch_size, seq len]\n",
    "        embedding = self.dropout(self.embedding(src)) #harry potter is\n",
    "        #embedding: [batch-size, seq len, emb dim]\n",
    "        output, hidden = self.lstm(embedding, hidden)\n",
    "        #ouput: [batch size, seq len, hid dim]\n",
    "        #hidden: [num_layers * direction, seq len, hid_dim]\n",
    "        output = self.dropout(output)\n",
    "        prediction =self.fc(output)\n",
    "        #prediction: [batch_size, seq_len, vocab_size]\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5A4sBKpgNIU"
   },
   "source": [
    "## 5. Training\n",
    "\n",
    "Follows very basic procedure.  One note is that some of the sequences that will be fed to the model may involve parts from different sequences in the original dataset or be a subset of one (depending on the decoding length). For this reason we will reset the hidden state every epoch, this is like assuming that the next batch of sequences is probably always a follow up on the previous in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1737885178357,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "mP0UP_ZuBSsJ",
    "outputId": "c6978015-d3ba-4175-f92e-0db2af6f152b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26763"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1737885180653,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "2V8nUhJYgNIU"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb_dim = 1024                # 400 in the paper\n",
    "hid_dim = 1024                # 1150 in the paper\n",
    "num_layers = 2                # 3 in the paper\n",
    "dropout_rate = 0.65\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1737885187205,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "eFUEX6U75Uch"
   },
   "outputs": [],
   "source": [
    "# save mode for webapp\n",
    "import pickle\n",
    "Data = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'emb_dim': emb_dim,\n",
    "    'hid_dim': hid_dim,\n",
    "    'num_layers': num_layers,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'tokenizer': tokenizer,\n",
    "    'vocab': vocab\n",
    "}\n",
    "\n",
    "pickle.dump(Data,open('models/vocab.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1737885203795,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "ZLVU_T6UgNIV",
    "outputId": "594f2b85-fff6-4469-c90a-87e07aaf4013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 71,630,987 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model      = LSTMLanguageModel(vocab_size, emb_dim, hid_dim, num_layers, dropout_rate).to(device)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737875257125,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "C1q954mqgNIV"
   },
   "outputs": [],
   "source": [
    "def get_batch(data, seq_len, idx):\n",
    "    #data #[batch size, bunch of tokens]\n",
    "    src    = data[:, idx:idx+seq_len]\n",
    "    target = data[:, idx+1:idx+seq_len+1]  #target simply is ahead of src by 1\n",
    "    return src, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737875257125,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "QdDpbjyJgNIV"
   },
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    # drop all batches that are not a multiple of seq_len\n",
    "    # data #[batch size, seq len]\n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]  #we need to -1 because we start at 0\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    #reset the hidden every epoch\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #hidden does not need to be in the computational graph for efficiency\n",
    "        hidden = model.detach_hidden(hidden)\n",
    "\n",
    "        src, target = get_batch(data, seq_len, idx) #src, target: [batch size, seq len]\n",
    "        src, target = src.to(device), target.to(device)\n",
    "        batch_size = src.shape[0]\n",
    "        prediction, hidden = model(src, hidden)\n",
    "\n",
    "        #need to reshape because criterion expects pred to be 2d and target to be 1d\n",
    "        prediction = prediction.reshape(batch_size * seq_len, -1)  #prediction: [batch size * seq len, vocab size]\n",
    "        target = target.reshape(-1)\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * seq_len\n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737875257125,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "cUGj9SDngNIV"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, num_batches - 1, seq_len):\n",
    "            hidden = model.detach_hidden(hidden)\n",
    "            src, target = get_batch(data, seq_len, idx)\n",
    "            src, target = src.to(device), target.to(device)\n",
    "            batch_size= src.shape[0]\n",
    "\n",
    "            prediction, hidden = model(src, hidden)\n",
    "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(prediction, target)\n",
    "            epoch_loss += loss.item() * seq_len\n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFtYfDC5gNIV"
   },
   "source": [
    "Here we will be using a `ReduceLROnPlateau` learning scheduler which decreases the learning rate by a factor, if the loss don't improve by a certain epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1580552,
     "status": "ok",
     "timestamp": 1737884431585,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "odgTZ7OdgNIV",
    "outputId": "587585f2-407d-4254-edc5-1e2c878ea38b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 766.564\n",
      "\tValid Perplexity: 441.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 443.863\n",
      "\tValid Perplexity: 347.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 369.021\n",
      "\tValid Perplexity: 305.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 327.099\n",
      "\tValid Perplexity: 282.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 298.128\n",
      "\tValid Perplexity: 266.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 275.441\n",
      "\tValid Perplexity: 255.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 257.433\n",
      "\tValid Perplexity: 248.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 242.276\n",
      "\tValid Perplexity: 243.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 229.148\n",
      "\tValid Perplexity: 239.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 217.475\n",
      "\tValid Perplexity: 236.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 207.265\n",
      "\tValid Perplexity: 236.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 197.716\n",
      "\tValid Perplexity: 235.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 189.355\n",
      "\tValid Perplexity: 235.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 177.512\n",
      "\tValid Perplexity: 237.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 170.582\n",
      "\tValid Perplexity: 235.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 167.958\n",
      "\tValid Perplexity: 234.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 165.961\n",
      "\tValid Perplexity: 234.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 164.506\n",
      "\tValid Perplexity: 234.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 163.704\n",
      "\tValid Perplexity: 234.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 163.514\n",
      "\tValid Perplexity: 232.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.887\n",
      "\tValid Perplexity: 233.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 163.093\n",
      "\tValid Perplexity: 232.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.622\n",
      "\tValid Perplexity: 232.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.506\n",
      "\tValid Perplexity: 232.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.498\n",
      "\tValid Perplexity: 232.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.762\n",
      "\tValid Perplexity: 232.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.649\n",
      "\tValid Perplexity: 232.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.609\n",
      "\tValid Perplexity: 232.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.643\n",
      "\tValid Perplexity: 232.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.501\n",
      "\tValid Perplexity: 232.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.624\n",
      "\tValid Perplexity: 232.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.636\n",
      "\tValid Perplexity: 232.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.750\n",
      "\tValid Perplexity: 232.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.641\n",
      "\tValid Perplexity: 232.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.594\n",
      "\tValid Perplexity: 232.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.520\n",
      "\tValid Perplexity: 232.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.668\n",
      "\tValid Perplexity: 232.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.550\n",
      "\tValid Perplexity: 232.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.719\n",
      "\tValid Perplexity: 232.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.768\n",
      "\tValid Perplexity: 232.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.619\n",
      "\tValid Perplexity: 232.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.585\n",
      "\tValid Perplexity: 232.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.668\n",
      "\tValid Perplexity: 232.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.696\n",
      "\tValid Perplexity: 232.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.561\n",
      "\tValid Perplexity: 232.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.562\n",
      "\tValid Perplexity: 232.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.579\n",
      "\tValid Perplexity: 232.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.398\n",
      "\tValid Perplexity: 232.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.740\n",
      "\tValid Perplexity: 232.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 162.631\n",
      "\tValid Perplexity: 232.081\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "seq_len  = 50 #<----decoding length\n",
    "clip    = 0.25\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "i = 1;\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_data, optimizer, criterion,\n",
    "                batch_size, seq_len, clip, device)\n",
    "    valid_loss = evaluate(model, valid_data, criterion, batch_size,\n",
    "                seq_len, device)\n",
    "\n",
    "    lr_scheduler.step(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
    "\n",
    "    print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
    "    # print number of ephoch\n",
    "    print(f'\\tEpoch: {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxDWl3JvgNIV"
   },
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6766,
     "status": "ok",
     "timestamp": 1737884438349,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "7EpV8zZzgNIV",
    "outputId": "d40b2ae3-8f2c-4a41-8d48-b645f667bad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perplexity: 227.200\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
    "test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
    "print(f'Test Perplexity: {math.exp(test_loss):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnnMrWBEgNIV"
   },
   "source": [
    "## 7. Real-world inference\n",
    "\n",
    "Here we take the prompt, tokenize, encode and feed it into the model to get the predictions.  We then apply softmax while specifying that we want the output due to the last word in the sequence which represents the prediction for the next word.  We divide the logits by a temperature value to alter the model’s confidence by adjusting the softmax probability distribution.\n",
    "\n",
    "Once we have the Softmax distribution, we randomly sample it to make our prediction on the next word. If we get <unk> then we give that another try.  Once we get <eos> we stop predicting.\n",
    "    \n",
    "We decode the prediction back to strings last lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1737884438350,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "EMfX8w9ogNIW"
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, device, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    model.eval()\n",
    "    tokens = tokenizer(prompt)\n",
    "    indices = [vocab[t] for t in tokens]\n",
    "    batch_size = 1\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_seq_len):\n",
    "            src = torch.LongTensor([indices]).to(device)\n",
    "            prediction, hidden = model(src, hidden)\n",
    "\n",
    "            #prediction: [batch size, seq len, vocab size]\n",
    "            #prediction[:, -1]: [batch size, vocab size] #probability of last vocab\n",
    "\n",
    "            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)\n",
    "            prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            while prediction == vocab['<unk>']: #if it is unk, we sample again\n",
    "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if prediction == vocab['<eos>']:    #if it is eos, we stop\n",
    "                break\n",
    "\n",
    "            indices.append(prediction) #autoregressive, thus output becomes input\n",
    "\n",
    "    itos = vocab.get_itos()\n",
    "    tokens = [itos[i] for i in indices]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1737884478739,
     "user": {
      "displayName": "Nyein Chan Aung",
      "userId": "10271779707834005263"
     },
     "user_tz": -420
    },
    "id": "6-T1jG3AgNIW",
    "outputId": "e5002376-1362-4a05-8371-e3e78bb673df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "my heart and mine , and i ' ll be so much i do not care\n",
      "\n",
      "0.7\n",
      "my heart and mine , and i ' d be so thou , i ' d be , and sighs , and shalt , and shall i love a better , even\n",
      "\n",
      "0.75\n",
      "my heart became mine\n",
      "\n",
      "0.8\n",
      "my heart became mine\n",
      "\n",
      "1.0\n",
      "my heart became mine to me , but not has built thou fair , and i with her , sighs , and shalt , and shall i go can he say ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'My heart'\n",
    "max_seq_len = 30\n",
    "seed = 0\n",
    "\n",
    "#smaller the temperature, more diverse tokens but comes\n",
    "#with a tradeoff of less-make-sense sentence\n",
    "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
    "for temperature in temperatures:\n",
    "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer,\n",
    "                          vocab, device, seed)\n",
    "    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dV88N338jXAR"
   },
   "source": [
    "# Reference\n",
    "- Dataset: https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems/data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a1b4511a3144a2a919cb822f71f693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a311d8d045e94cd389b7eac7ca75424e",
      "placeholder": "​",
      "style": "IPY_MODEL_598afe639ee14c24b898db8db7acbf35",
      "value": " 72816/72816 [00:04&lt;00:00, 17028.73 examples/s]"
     }
    },
    "0b469d200c324c47b782f084c0d3e43d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d7174f49f9c45c4bea22cbe2c2a166a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d049fb9058ae4b4d8e7b0f3423c6dbd4",
      "placeholder": "​",
      "style": "IPY_MODEL_7b32a7bcbd9a4589b178837590d77e98",
      "value": "Map: 100%"
     }
    },
    "1eeb99ca22c342069d33b6fae1f4017f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25439d3b31e74d008f2d5671efe2e10f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e708c16828274a6187abed31982fc17f",
      "placeholder": "​",
      "style": "IPY_MODEL_0b469d200c324c47b782f084c0d3e43d",
      "value": " 9102/9102 [00:00&lt;00:00, 18029.20 examples/s]"
     }
    },
    "439cc7aca2604e31bf7a1a438e6c207c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff299a29bd794f65bffc5afebf25a08c",
      "max": 72816,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7448d3c87600403f850c1b11091cadbc",
      "value": 72816
     }
    },
    "521d4ae75430408b8a095187c9d7c009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5665e5ee3d564db59871b3c097e9b7f2",
      "max": 9102,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59cd518511c14f8b8597a6111769c27b",
      "value": 9102
     }
    },
    "5665e5ee3d564db59871b3c097e9b7f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "598afe639ee14c24b898db8db7acbf35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59cd518511c14f8b8597a6111769c27b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e606082e7cf4322ae384b0998c6c870": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7006cd37f86142c693ad2c1d61fa87d5",
      "max": 9102,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd0556ca3bcb424cba3fbcbe72b72f7a",
      "value": 9102
     }
    },
    "7006cd37f86142c693ad2c1d61fa87d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7448d3c87600403f850c1b11091cadbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "786c0c40bcb74b9e80a8fbe386f467a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d7174f49f9c45c4bea22cbe2c2a166a",
       "IPY_MODEL_6e606082e7cf4322ae384b0998c6c870",
       "IPY_MODEL_afb75a221e264882bcd4155c86415060"
      ],
      "layout": "IPY_MODEL_c9a7133468304f76ab45d141fe9b9a51"
     }
    },
    "79716e5177324c57b762e70c6ef1de48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85d9b10c1cab4c788955729fd0812a0d",
      "placeholder": "​",
      "style": "IPY_MODEL_b03122a63c3e4839b8ce35b9ffd648f8",
      "value": "Map: 100%"
     }
    },
    "7b32a7bcbd9a4589b178837590d77e98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cdcf56e94b44ffba2d32d78ae0ee677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85d9b10c1cab4c788955729fd0812a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "864766d852b54e389eaaf5ce6b95d7b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79716e5177324c57b762e70c6ef1de48",
       "IPY_MODEL_521d4ae75430408b8a095187c9d7c009",
       "IPY_MODEL_25439d3b31e74d008f2d5671efe2e10f"
      ],
      "layout": "IPY_MODEL_7cdcf56e94b44ffba2d32d78ae0ee677"
     }
    },
    "900ac4d1f4f54797b2388d777ab37197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a311d8d045e94cd389b7eac7ca75424e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a392f6a53c2148ce96ef638bd5d52d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afb75a221e264882bcd4155c86415060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4abfbe5691e4fd399903a384b518271",
      "placeholder": "​",
      "style": "IPY_MODEL_a392f6a53c2148ce96ef638bd5d52d7f",
      "value": " 9102/9102 [00:00&lt;00:00, 16728.95 examples/s]"
     }
    },
    "b03122a63c3e4839b8ce35b9ffd648f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4abfbe5691e4fd399903a384b518271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6ad48b766334141b1d83a164c694212": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d43fddb3cd544d4a9c27151d2d73a43c",
      "placeholder": "​",
      "style": "IPY_MODEL_900ac4d1f4f54797b2388d777ab37197",
      "value": "Map: 100%"
     }
    },
    "c9a7133468304f76ab45d141fe9b9a51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd0556ca3bcb424cba3fbcbe72b72f7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d049fb9058ae4b4d8e7b0f3423c6dbd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d43fddb3cd544d4a9c27151d2d73a43c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e708c16828274a6187abed31982fc17f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7adc43502ef43ef820881de2101c164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6ad48b766334141b1d83a164c694212",
       "IPY_MODEL_439cc7aca2604e31bf7a1a438e6c207c",
       "IPY_MODEL_00a1b4511a3144a2a919cb822f71f693"
      ],
      "layout": "IPY_MODEL_1eeb99ca22c342069d33b6fae1f4017f"
     }
    },
    "ff299a29bd794f65bffc5afebf25a08c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
